
---
layout: post
title:  "2018-10-20-네이트크롤링-낚시성 단어 선정"
date:   2018-10-17 16:22:25
categories: Data_science
permalink: pretty
---

**네이트뉴스 크롤링 - feature 뽑기 1차**
===================

네이트뉴스를 크롤링해서 낚시성 기사의 특징을 추출해내어 낚시성 기사 분류기를 만들어보고 싶었다.

내가 생각하고 있는 '낚시성 기사'의 기준은
**"제목과 기사의 내용이 다른" 기사**이다.

예를 들면 다음과 같다. 
> 제목 : 아이유, 노래 뿐만 아니라 축구도 신동? 
> 내용 : 축구선수 안드레 아이유가 골을 넣었다.

이런 낚시성 기사에 속는다면 왠지 모르게 어이가 없을 것 같다고 생각이 들었다.

그래서 보통 낚시성 기사에서 자주 나오는 낚시성 단어에는 어떤 것들이 있을지 크롤링을 통해 한번 알아보았다.

```
import pandas
from konlpy.tag import Twitter
from collections import Counter
```
```
hoax = pandas.read_csv("hoax(080101-080331).csv", encoding="cp949")
data["title"][0:3]
```
>결과는 요렇게 나왔다.
>
>0  SBS연기대상 불륜과 사채업자 SBS 휩쓸다(종합)
1    ‘헨젤과 그레텔’ 동화 VS 영화 무엇이 다를까?(헨젤과 그레텔①）
2                  '산소탱크' 박지성, '무자년은 나의 해'
Name: title, dtype: object

```
titles=[]
for title in hoax["title"]:
    titles.append(title)
    
pos = Twitter().pos(str(titles))
counter = Counter(pos)

common_words = counter.most_common(60)
common_words
```
코드를 실행하면,

[(("'", 'Punctuation'), 1357),
 (("',", 'Punctuation'), 739),
 ((',', 'Punctuation'), 538),
 (('"', 'Punctuation'), 392),
 (('"\',', 'Punctuation'), 192),
 (('에', 'Josa'), 182),
 (('‘', 'Foreign'), 167),
 (('’', 'Foreign'), 167),
 (('",', 'Punctuation'), 164),
 (('다', 'Eomi'), 159),
 ((']', 'Punctuation'), 148),
 (('“', 'Foreign'), 144),
 (('”', 'Foreign'), 143),
 (('의', 'Josa'), 132),
 (('-', 'Punctuation'), 121),
 (('…', 'Foreign'), 116),
 (('"\'', 'Punctuation'), 104),
 (("'[", 'Punctuation'), 102),
 (("?',", 'Punctuation'), 99),
 (('이', 'Josa'), 90),
 (('은', 'Josa'), 90),
 (('\'",', 'Punctuation'), 78),
 (("'<", 'Punctuation'), 77),
 (('는', 'Josa'), 72),
 (('포토', 'Noun'), 68),
 (('들', 'Suffix'), 63),
 (('1', 'Number'), 63),
 (('가', 'Josa'), 63),
 (('로', 'Josa'), 59),
 (('"[', 'Punctuation'), 59),
 (('요', 'Eomi'), 56),
 (("\\'", 'Punctuation'), 55),
 (('사진', 'Noun'), 54),
 (('?', 'Punctuation'), 53),
 (('서', 'Josa'), 52),
 (('2', 'Number'), 51),
 (('>', 'Punctuation'), 50),
 (('과', 'Josa'), 49),
 (('년', 'Noun'), 46),
 (('\'"', 'Punctuation'), 44),
 (('도', 'Josa'), 44),
 (('엔', 'Josa'), 43),
 (('한', 'Josa'), 43),
 (('와', 'Josa'), 40),
 (('박지성', 'Noun'), 39),
 (('한국', 'Noun'), 39),
 (('으로', 'Josa'), 39),
 (('(', 'Punctuation'), 37),
 (('결혼', 'Noun'), 35),
 (('일', 'Noun'), 34),
 (('"<', 'Punctuation'), 33),
 (('·', 'Foreign'), 33),
 (('을', 'Josa'), 32),
 (("!',", 'Punctuation'), 31),
 (('것', 'Noun'), 30),
 (('?",', 'Punctuation'), 30),
 (('에서', 'Josa'), 29),
 (('나', 'Eomi'), 29),
 ((")',", 'Punctuation'), 28),
 (('전', 'Noun'), 28)]

위와 같은 결과가 나온다.


이제 나머지 코드를 정리해주자.
```
normal = pandas.read_csv("normal.csv", encoding="cp949")

titles_normal=[]
for title in normal["title"]:
    titles_normal.append(title)

pos_normal = Twitter().pos(str(titles_normal))
counter_normal = Counter(pos_normal)
common_words_normal = counter_normal.most_common(30)
common_words_normal
```

낚시성 단어를 정리해주는 것으로 이번 크롤링도 마무리 해야겠다! XD
```
hoax_words_list = ['…', '?', '포토', '사진', '박지성', '한국', '결혼', '일', '!']
```